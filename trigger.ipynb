{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Crawling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrapy project is under this [directory](https://github.com/iou2much/NLP-tasks/tree/master/banks_crawler/banks_crawler). This [crawler](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/banks_crawler/spiders/cncb.py) implements the data extraction . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chibs/.conda/envs/ml-learning-py3/lib/python3.6/site-packages/ipykernel_launcher.py:5: ScrapyDeprecationWarning: Importing from scrapy.xlib.pydispatch is deprecated and will no longer be supported in future Scrapy versions. If you just want to connect signals use the from_crawler class method, otherwise import pydispatch directly if needed. See: https://github.com/scrapy/scrapy/issues/1762\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing.queues import Queue\n",
    "from scrapy import  signals \n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.xlib.pydispatch import dispatcher\n",
    "from scrapy.utils.project import get_project_settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "import os.path\n",
    "from stanza.nlp.corenlp import CoreNLPClient\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is an function start the scrapy project to crawl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrawlerWorker(multiprocessing.Process):\n",
    "    def __init__(self, result_queue, spider, settings=None):\n",
    "        multiprocessing.Process.__init__(self)\n",
    "        self.settings = settings or get_project_settings()\n",
    "        self.result_queue = result_queue\n",
    "        self.spider = spider\n",
    "        self.items = []\n",
    "        dispatcher.connect(self._item_scraped, signals.item_scraped)\n",
    "\n",
    "    def _item_scraped(self, item):\n",
    "        self.items.append(item)\n",
    "\n",
    "    def run(self):\n",
    "        self.crawler_process = CrawlerProcess(self.settings)\n",
    "        crawler = self.crawler_process.create_crawler(self.spider)\n",
    "        self.crawler_process.crawl(crawler)\n",
    "        self.crawler_process.start()\n",
    "        self.result_queue.put(self.items)\n",
    "        self.crawler_process.stop()\n",
    "\n",
    "def crawl():\n",
    "    result_queue = Queue(ctx=multiprocessing.get_context())\n",
    "    crawler = CrawlerWorker(result_queue, \"cncb\")\n",
    "    crawler.start()\n",
    "    return result_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'cncb-qna.csv'\n",
    "if os.path.isfile(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    result = crawl()\n",
    "    df = pd.DataFrame(result,columns=['category', 'question', 'answer', 'language'])\n",
    "    df.to_csv('cncb-qna.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Language Vector Space Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Introduction for the dicts\n",
    "[dict.txt](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/dics/dict.txt) is the default dict of jieba. I use [sc2tc.py]https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/dics/sc2tc.py) to generate a traditional version, [dict-tc.txt](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/dics/dict-tc.txt).\n",
    "\n",
    "[sougou.dict](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/dics/sougou.dict) is generate from some dicts of [Sougou's](http://pinyin.sogou.com/dict/). The Sougou's dicts are in scel format. So I use this [script](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/dics/scel2txt.py) to convert them into text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2017-05-15 18:58:01,286 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/3b/lpzhjvns3q501g94r7r8nkxw0000gn/T/jieba.cache\n",
      "2017-05-15 18:58:01,289 : DEBUG : Loading model from cache /var/folders/3b/lpzhjvns3q501g94r7r8nkxw0000gn/T/jieba.cache\n",
      "Loading model cost 0.865 seconds.\n",
      "2017-05-15 18:58:02,153 : DEBUG : Loading model cost 0.865 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-05-15 18:58:02,155 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"dics/dict-tc.txt\")\n",
    "jieba.load_userdict(\"dics/sougou.dict\")\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DocAnalyzer* is the implements for these tasks:\n",
    "\n",
    "### 2.1 Tokenize questions into words¶\n",
    "\n",
    "    tokenize() method tokenizes some docs.\n",
    "\n",
    "### 2.2 Build a TFIDF model using questions and answers\n",
    "    build_tfidf_model() builds a TFIDF model.\n",
    "### 3. Similarity Comparison\n",
    "    similarity() returns the most similar sentence.\n",
    "### 4. Named Entity Recognition\n",
    "    get_entities() returns the list of entities in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DocAnalyzer:\n",
    "    def __init__(self,docs):\n",
    "        self.texts = []\n",
    "        self.dic = None\n",
    "        self.tfidf = None\n",
    "        self.corpus = None\n",
    "        self.dic_length = 0\n",
    "        self.coreNLP_client = None\n",
    "        self.tokenize(docs)\n",
    "    \n",
    "    def tokenize(self,docs):\n",
    "        words=[]\n",
    "        punct = set(u'''， %/:!),.:;?]}¢'\"、。〉》」』】〕〗〞︰︱︳﹐､﹒\n",
    "        ﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠\n",
    "        々‖•·ˇˉ―--′’”([{£¥'\"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻\n",
    "        ︽︿﹁﹃﹙﹛﹝（｛“‘-—_…''')\n",
    "        # for str/unicode\n",
    "        filterpunt = lambda s: ''.join(filter(lambda x: x not in punct, s))\n",
    "        # for list\n",
    "        filterpuntl = lambda l: list(filter(lambda x: x not in punct, l))\n",
    "\n",
    "        for doc in docs.map(lambda x:jieba.cut(str(x))):\n",
    "            words.append(filterpuntl(list(doc)))\n",
    "\n",
    "        frequency = defaultdict(int)\n",
    "        for text in words:\n",
    "            for token in text:\n",
    "                frequency[token] += 1\n",
    "        self.texts = [[token for token in text if frequency[token] > 1] for text in words]\n",
    "    \n",
    "    def build_tfidf_model(self):\n",
    "        dic = corpora.Dictionary(self.texts)\n",
    "        self.dic = dic\n",
    "        self.dic_length = len(dic)\n",
    "        dic.save('/tmp/cncb-qna.dict')\n",
    "        self.corpus = [dic.doc2bow(text) for text in self.texts]\n",
    "        corpora.MmCorpus.serialize('/tmp/cncb-qna.mm', self.corpus)\n",
    "        self.tfidf = models.TfidfModel(self.corpus)\n",
    "        \n",
    "    def similarity(self,sentence):\n",
    "        if self.tfidf is None:\n",
    "            self.build_tfidf_model()\n",
    "        index = similarities.SparseMatrixSimilarity(self.tfidf[self.corpus], num_features=self.dic_length)\n",
    "        \n",
    "        new_vec = self.dic.doc2bow(jieba.cut(sentence))\n",
    "        similary = tuple(enumerate(index[self.tfidf[new_vec]]))\n",
    "        index,sim = max(similary, key=lambda x:x[1])\n",
    "        return sim,''.join(self.texts[index])\n",
    "\n",
    "    def get_coreNLP_client(self):\n",
    "        if self.coreNLP_client is None:\n",
    "            self.coreNLP_client = CoreNLPClient(server='http://localhost:9000', default_annotators=['ssplit', 'lemma', 'tokenize', 'pos', 'ner']) \n",
    "            \n",
    "        return self.coreNLP_client\n",
    "        \n",
    "    def get_entities(self, sentence):\n",
    "        client = self.get_coreNLP_client()\n",
    "        \n",
    "        annotated = client.annotate(sentence)\n",
    "        result = []\n",
    "        for s in annotated.sentences:\n",
    "            for token in s:\n",
    "                if token.ner != 'O':\n",
    "                    result.append((token.word, token.ner))\n",
    "        return result\n",
    "\n",
    "analyzer = DocAnalyzer(df.question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test *similarity()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum similary is 0.55071: 如果我想取消正在处理中或已部份成交的指令我可以怎样做\n"
     ]
    }
   ],
   "source": [
    "print('The maximum similary is %s: %s'%analyzer.similarity('取消正在处理的指令'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test * get_entities() *\n",
    "Before you test the get_entities() method, the ** StanfordCoreNLPServer ** should be launched already.\n",
    "\n",
    "The installation guide of StanfordCoreNLPServer is on [Stanford Site](https://nlp.stanford.edu/software/CRF-NER.shtml)\n",
    "\n",
    "The package I use here are,\n",
    "* **[CoreNLP](https://stanfordnlp.github.io/CoreNLP/)**\n",
    "* **[Named Entity Recognizer version 3.7.0](https://nlp.stanford.edu/software/CRF-NER.shtml#Download)**,\n",
    "* **[3.7.0 Chinese models\n",
    "](https://nlp.stanford.edu/software/stanford-chinese-corenlp-2016-10-31-models.jar) **, \n",
    "* ** [3.7.0 English models](https://nlp.stanford.edu/software/stanford-english-corenlp-2016-10-31-models.jar) **\n",
    "\n",
    "After deploy the package into the Standford directory, set an English-Chinese supported configuraion in the ** [custom.properties](https://github.com/iou2much/NLP-tasks/blob/master/banks_crawler/StanfordNLP/corenlp/custom.properties) **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess,time\n",
    "def start_stanfordNLP_server():\n",
    "    command = \"ps aux|grep StanfordCoreNLPServer\"\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=None, shell=True)\n",
    "    output = process.communicate()\n",
    "    if len(output) > 1 and 'edu.stanford.nlp.pipeline.StanfordCoreNLPServer' in str(output[0]) :\n",
    "        stop_stanfordNLP_server()\n",
    "        time.sleep(3)\n",
    "\n",
    "    command=\"\"\"\n",
    "    java -Xmx4g -cp \\\n",
    "    \"StanfordNLP/corenlp/*:StanfordNLP/corenlp/:StanfordNLP/ner/:StanfordNLP/parser/:StanfordNLP/postagger/\" \\\n",
    "    edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n",
    "    -serverProperties StanfordNLP/corenlp/custom.properties \\\n",
    "    -port 9000 -timeout 15000 &\n",
    "    \"\"\"\n",
    "    print('starting the stanfordNLP server')\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "    output = process.communicate()\n",
    "def stop_stanfordNLP_server():\n",
    "    command=\"\"\"!ps aux|grep StanfordCoreNLPServer|awk '{print $2}'|xargs kill -9 > /dev/null 2>&1\"\"\"\n",
    "    print('killing the stanfordNLP server')\n",
    "    subprocess.call(command, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "killing the stanfordNLP server\n",
      "starting the stanfordNLP server\n"
     ]
    }
   ],
   "source": [
    "start_stanfordNLP_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the get_entities() method. At the first time you invoke it, please wait a few seconds, cuz it will load the model for the first time. As we can see here, the default Chinese model of Stanford NER is not good enough, it regconize 星期天 as NUMBER. If we use some customized corpus to train the data, it might be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('星期天', 'NUMBER'), ('北京', 'GPE'), ('会', 'NUMBER')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[('Rami', 'PERSON'), ('Eid', 'PERSON'), ('Stony', 'ORGANIZATION'), ('Brook', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('NY', 'LOCATION'), ('Beckham', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.get_entities(\"这个星期天北京会下雨\"))\n",
    "print('-'*100)\n",
    "print(analyzer.get_entities('Rami Eid is studying at Stony Brook University in NY,America.I don\\'t like Beckham.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Voice Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, most of my time is spending on the data preprocessing.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "I find this large \"tagged\" corpus for this, since there's hardly a large Cantonese dataset on line.\n",
    "* [Bible Audio in Cantonese](http://disc.fuyin.tv/soft/html/582.html)\n",
    "* [Textbook](http://download.o-bible.com:8080/hgb.gz)\n",
    "\n",
    "When I say tagged, actually it's not. It also has some issue to fix before I use it.\n",
    "* The audio file are in chapters, ie, per chapter every audio file. It will be too long for the input of the deep network. So it should be split into smaller files.\n",
    "* The content of the audio and the text are exactly the same, but after the audio files are splitted, the text should be dealed with too.\n",
    "\n",
    "Also, for a real world application, this dataset is too ideal. \n",
    "* Cuz it's Bible, the reading speed is too steady and slow. \n",
    "* Plus, there's no background noises at all in these audio. When we use the model trained with it, we might hardly catch the background noises feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework\n",
    "For this task, I use mozilla's [DeepSpeech project](https://github.com/mozilla/DeepSpeech) It's based on Baidu's Deep Speech research paper, implemented on Tensorflow, and supported [warp-CTC](https://g,ithub.com/baidu-research/warp-ctc).\n",
    "\n",
    "Besides, it's only supporting characters in Alphabet . So I encode the Chinese characters before input into the DNN, and decode the output of forward results. The mapping data is in this [file](https://github.com/iou2much/NLP-tasks/blob/master/asr_for_cantonese/dataset/char_map.txt).\n",
    "\n",
    "Like these,\n",
    "\n",
    "    飘 djh\n",
    "    尼 dji\n",
    "    怪 djj\n",
    "    赠 djk\n",
    "    占 djl\n",
    "    掐 djm\n",
    "    齐 djn\n",
    "    篷 djo\n",
    "    ......\n",
    "    \n",
    "\n",
    "This approach has some issue too, the model will only learn the vocal features ,but not learn the language feature. Also the model use Levenshtein distance as a optimal target, so when it predict a character from audio, it will return a result with a minimum edit distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a glance of the codes for the tasks mention above.\n",
    "\n",
    "In ** [asr_for_cantonese/format.py](https://github.com/iou2much/NLP-tasks/blob/master/asr_for_cantonese/format.py) **\n",
    "\n",
    "* **mp3toWav**: convent mp3 to wav format\n",
    "* **formatTxt**: split the text book into chapters like audio file\n",
    "* **char_map**: generate the char_map.txt\n",
    "* **encode_str & decode_str **: encode or decode the Chinese character to Alphabet\n",
    "\n",
    "\n",
    "In ** [asr_for_cantonese/split.py](https://github.com/iou2much/NLP-tasks/blob/master/asr_for_cantonese/split.py) **\n",
    "* **split_wav** : split a big wav file into pieces, and split the relevant text .\n",
    "* **split_txt** : split the training and validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I get a bunch of wav files, and a ** [csv file](https://github.com/iou2much/NLP-tasks/blob/master/asr_for_cantonese/dataset/trans.full.csv)** to input into the DeepSpeech model. \n",
    "\n",
    "And run ** [this script](https://github.com/iou2much/NLP-tasks/blob/master/asr_for_cantonese/bin/run-bibles.sh) ** to start training the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the following code, please compile the Tensorflow lib and DeepSpeech navtive client.Just follow this [guide](https://github.com/mozilla/DeepSpeech/tree/master/native_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: bvq wj abi dgs a cyi cbt bkk cqr ado rw c gm ml \n",
      "Chinese: 亚伯横就撇着耶和华脐山孽胳久\n",
      "----------------------------------------------------------------------------------------------------\n",
      "code: pj crd awp am aqk aaj aml \n",
      "Chinese: 不然你实在笑了\n",
      "----------------------------------------------------------------------------------------------------\n",
      "code: bqs ayq alk pu bqb re cdo cjg crd biv cju dcd csn dbl ays bso deg cdo xx dkl ckh dby dgx ata bud pj crd ays bnk dcl aku bch \n",
      "Chinese: 察看他们所行的果然尽像那达到我耳中的声音一样吗若是不然我也必知道\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import scipy.io.wavfile as wav\n",
    "from deepspeech import DeepSpeech\n",
    "from asr_for_cantonese.format import decode_str\n",
    "\n",
    "# The model is over hundred megabytes, I\n",
    "model_path = '/Users/chibs/playground/bigdata-stack/themes/speech-reg/DeepSpeech/bibles_export/output_graph.pb'\n",
    "ds = DeepSpeech(model_path, 26, 9)\n",
    "\n",
    "fs, audio = wav.read('test_data/12_chunk_05.wav')\n",
    "output = ds.stt(audio, fs)\n",
    "print('code: %s '%output)\n",
    "print('Chinese: %s'%decode_str(output))\n",
    "print('-'*100)\n",
    "\n",
    "fs, audio = wav.read('test_data/18_chunk_32.wav')\n",
    "output = ds.stt(audio, fs)\n",
    "print('code: %s '%output)\n",
    "print('Chinese: %s'%decode_str(output))\n",
    "print('-'*100)\n",
    "\n",
    "fs, audio = wav.read('test_data/18_chunk_42.wav')\n",
    "output = ds.stt(audio, fs)\n",
    "print('code: %s '%output)\n",
    "print('Chinese: %s'%decode_str(output))\n",
    "print('-'*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last one is from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: h cak  bkb api cnf bfs cxo ays cdo byj kc bau w dek bqb avw aeh bud ei ahn cdo dcd awm bqk cbt bkk cqr apm cnc bqb bxi ak bpkk bbu brq vc axg al ks cbt bkk cqr cdo ael xi bnk aes jm vk a \n",
      "Chinese: 罗得诓卑见约笼我的惭烘原鸿络所育都是父追的那害羔耶和华官环所多玛摩拉圆毁埠堂耶和华的熔子也将埃及撇\n",
      "0.5306122448979592\n"
     ]
    }
   ],
   "source": [
    "#the sentence from the original text\n",
    "a='罗得举看见约旦河的全平原直到琐珥都是滋润的那地在耶和华未灭所多玛摩拉以先如同耶和华的园子也像埃及地'\n",
    "fs, audio = wav.read('test_data/13_chunk_14.wav')\n",
    "output = ds.stt(audio, fs)\n",
    "b=decode_str(output)\n",
    "print('code: %s '%output)\n",
    "print('Chinese: %s'%b)\n",
    "\n",
    "\n",
    "correct=0\n",
    "for i in range(len(a)):\n",
    "    if a[i]==b[i]:\n",
    "        correct+=1\n",
    "print(correct/len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I hope I explain well enough, but I just provide the result here. The whole workflow , including data preprocessing part and training part , should be written into an automatic script, but I haven't had time to do it yet. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you.\n",
    "That's all the work I've done. Thanks for your time.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
